{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOliOOco24EeYphebQv0R06",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sathizz7/Prase-Json/blob/main/Prase_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Screenin Test"
      ],
      "metadata": {
        "id": "tM94jEavXWSD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E2KYUk3_LFg7"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LinearRegression, Ridge,Lasso, ElasticNet,SGDRegressor, LogisticRegression\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.svm import SVR,SVC\n",
        "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor , GradientBoostingRegressor,RandomForestClassifier,GradientBoostingClassifier\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import ExtraTreesClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prase_json(json_file):\n",
        "  with open(json_file) as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  #1 Read the target and type of regression to be run\n",
        "\n",
        "  session_name = data['session_name']\n",
        "  if session_name == 'test':\n",
        "    project_id = '1'\n",
        "    df = pd.read_csv('iris.csv')\n",
        "\n",
        "  target = data['target']\n",
        "  predction_type = data['predction_type']\n",
        "  \n",
        "  #2Read the features and apply missing imputation\n",
        "\n",
        "  feature = data['feature']\n",
        "  imputer = SimpleImputer()\n",
        "  df[feature] = imputer.fit_transform(df[feature])\n",
        "\n",
        "  #3 : Compute feature reduction\n",
        "\n",
        "  feature_reduction = data['feature_reduction']\n",
        "  if feature_reduction == 'No Reduction':\n",
        "    pass\n",
        "  elif feature_reduction == 'Corr with target':\n",
        "    corr_matrix = df[feature + [target]].corr()\n",
        "    corr_with_target = corr_matrix[target].sort_values(ascending = False)\n",
        "    relevant_features = corr_with_target[abs(corr_with_target) > 0.5]\n",
        "    df = df[relevant_features]\n",
        "  elif feature_reduction =='PCA':\n",
        "    pca = PCA(n_componets = 0.95)\n",
        "    df[feature] = pca.fit_transform(df[feature])\n",
        "\n",
        "  #4.Make the model objects\n",
        "\n",
        "  hyperparameters = data['hyperparameters']\n",
        "  gird_search = GridSearchCV(model, params= [], cv =5)\n",
        "  gird_search.fit(df[feature], df[target])\n",
        "  best_model = gird_search.best_estimators_\n",
        "  predctions = best_model.predict(df[feature])\n",
        "\n",
        "  #weight\n",
        "  #5\n",
        "  algorithms = data['algorithms']\n",
        "  if data['model_name'] == 'RandomForestRegressor':\n",
        "    model = RandomForestRegressor(min_trees = 10, max_trees = 30, feature_sampling_statergy = 'Default',\n",
        "                                  min_depth = 20, max_depth = 30, min_samples_per_leaf_min_values = 5, min_samples_per_leaf_max_value = 50, parallelism = 0)\n",
        "  \n",
        "  elif data['model_name'] == 'RandomForestClassifier':\n",
        "    model = RandomForestClassifier(min_trees = 20, feature_sampling_startergy = 'Default', min_depth = 20, max_depth = 25,\n",
        "                                   min_samples_per_leaf_min_value = 5, min_samples_per_leaf_max_value = 10, parallelism = 0)\n",
        "  \n",
        "  elif data['model_name'] == 'GBTClassifier':\n",
        "    model = GradientBoostingRegressor(num_of_BoostingStages = [67, 89], feature_sampling_startergy = 'Fixed_number', learning_rate = [], use_deviance = True, use_exponential = False,fixed_number = 22 , min_subsample = 1, max_subsample = 2, min_stepsize = 0.1, max_stepsize = 0.5, min_iter = 20, max_iter = 30, min_depth = 5, max_depth = 7)\n",
        "  \n",
        "  elif data['model_name'] == 'GBTRegressor':\n",
        "    model = GradientBoostingClassifier(num_of_BoostingStages = [67, 89], feature_sampling_startergy = 'Fixed_number', use_deviance = True, use_exponential = False,fixed_number = 22 , min_subsample = 1, max_subsample = 2, min_stepsize = 0.1, max_stepsize = 0.5, min_iter = 20, max_iter = 30, min_depth = 5, max_depth = 7)\n",
        "\n",
        "  elif data['model_name'] == 'LinearRegression':\n",
        "    model = LinearRegression(parallelism = 2, min_iter = 30, max_iter = 50, min_reparam = 0.5, max_regparam = 0.8, min_elasticnet = 0.5, max_elasticnet = 0.8)\n",
        "    \n",
        "    model = LogisticRegression(parallelism = 2, min_iter = 30, max_iter = 50, min_regparam = 0.5, max_regparam = 0.8, min_elasticnet = 0.5, max_elasticnet = 0.8)\n",
        "\n",
        "  elif data['model_name'] == 'Ridge Regression':\n",
        "    model = Ridge(regularization_term = 'specific values to rest', min_iter = 50, max_iter = 50, min_regparam = 0.5, max_regparam = 0.8)\n",
        "\n",
        "  elif data['model_name'] == 'Lasso Regression':\n",
        "    model = Lasso(regularization_term = 'specific values to rest', min_iter = 50, max_iter = 50, min_regparam = 0.5, max_regparam = 0.8)\n",
        "\n",
        "  elif data['model_name'] == 'ElasticNet Regression':\n",
        "    model = ElasticNet(regularization_term = 'specific values to rest', min_iter = 50, max_iter = 50, min_regparam = 0.5, max_regparam = 0.8)\n",
        "\n",
        "  elif data['model_name'] == 'xg_boost':\n",
        "    model = GradientBoostingRegressor(use_gradient_boosted_tree = True, dart = True, tree_method = '', random_state = 0, max_num_of_trees = 0, early_stopping = True, early_stopping_rounds = 2, max_depth_of_tree = [56,89], learningRate = [89, 76],l1_regularization = [77], l2_regularization = [78],gamma = [68],min_child_weight = [67], sub_sample = [67], col_sample_by_tree = [67], replace_missing_values = False, parallelism = 0)\n",
        "  elif data['model_name'] == 'DecisionTreeRegressor':\n",
        "    model = DecisionTreeRegressor(min_depth = 4, max_depth = 7, use_gini = False, use_entropy = True, min_sample_per_leaf = [12,6], use_best = True, use_random = True)\n",
        "\n",
        "  elif data['model_name'] == 'SVM':\n",
        "    model = SVR(linear_kernal = True, rep_kernal = True, ploynomial_kernal = True, sigmoid_kernal = True, c_value = [566, 78], auto = True, scale =True, custom_gamma_values = True, tolerance = 7, max_iteration = 7)\n",
        "  \n",
        "  elif data['model_name'] == 'SGD':\n",
        "    model = SGDRegressor(use_logistics = True, use_modified_hubber_loss = False, tolerance = 56,use_l1_regularization = 'on', use_l2_regularization = True, alpha_value = [79,56], parallelism = 1)\n",
        "  \n",
        "  elif data['moddel_name'] == 'KNN':\n",
        "    model = KNeighborsRegressor(k_value = [78], distance_weighting = True, neighbour_finding_algorithm = 'Automatic', random_state = 0, p_value = 0)\n",
        "  \n",
        "  elif data['model_name'] == 'Extra Random Trees':\n",
        "    model = ExtraTreesClassifier(num_of_trees = [40,489],feature_sampling_startergy = 'squre root and Logorithm', max_depth = [12, 45], min_samples_per_leaf = [78, 56], parallelism = 3)\n",
        "\n",
        "  elif data['model_name'] == 'Neural_network':\n",
        "    model = MLPClassifier(hidden_layer_sizes = [67, 89], activation = '', alpha_value = 0, max_iterations = 0, convergence_tolerance = 0, early_stopping = True, solver = 'ADAM', shuffle_data = True,initial_learning_rate = 0 , automatic_batching = True, beta_1 = 0, beta_2 = 0, epsilon = 0, power_t = 0, momentum = 0, use_nesterov_momentum = False)\n",
        "\n",
        "# Logloss\n",
        "\n",
        "  predction_type = data['predction_type']\n",
        "  if predction_type == 'regression':\n",
        "    mae = mean_absolute_error(df[target], predctions)\n",
        "    mse = mean_squared_error(df[target], predctions)\n",
        "    r2_score = r2_score(df[target],predctions)"
      ],
      "metadata": {
        "id": "tefgtB7RPgqk"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}